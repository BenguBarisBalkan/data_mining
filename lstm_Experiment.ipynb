{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1151420d-14fb-4f3c-90e3-afe36ecdeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53da0b54-0b6c-4f22-8bd4-b4efac58b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern\n",
      "no-pattern       11909\n",
      "BearButterfly      910\n",
      "BearShark          782\n",
      "BullBat            734\n",
      "BullButterfly      703\n",
      "BearCrab           569\n",
      "BullShark          544\n",
      "BullGartley        430\n",
      "BullCrab           310\n",
      "BullCypher         254\n",
      "BearGartley        197\n",
      "BearCypher         131\n",
      "BearBat             23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the labeled data produced by your friend's algorithm\n",
    "df = pd.read_csv(\"patterns.csv\")\n",
    "\n",
    "# Ensure date is a datetime (sorting is optional if you are sure it's already sorted)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\")  # harmless even if already sorted\n",
    "\n",
    "# Clean up the pattern column (replace missing with 'no-pattern', ensure string type)\n",
    "df[\"pattern\"] = df[\"pattern\"].fillna(\"no-pattern\").astype(str)\n",
    "\n",
    "# Just to understand the distribution of labels (not used for grouping)\n",
    "pattern_counts = df[\"pattern\"].value_counts()\n",
    "print(pattern_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23df5a58-1463-41e4-97b9-a8d7873ef8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups (pattern segments): 201\n"
     ]
    }
   ],
   "source": [
    "# Create a shifted version of pattern to compare with previous row\n",
    "df[\"pattern_shift\"] = df[\"pattern\"].shift(1)\n",
    "\n",
    "# Whenever pattern changes from previous row, we start a new group\n",
    "df[\"new_group\"] = (df[\"pattern\"] != df[\"pattern_shift\"]).astype(int)\n",
    "\n",
    "# Cumulative sum of new_group gives us a unique group id\n",
    "df[\"group_id\"] = df[\"new_group\"].cumsum()\n",
    "\n",
    "# Let's see how many groups there are\n",
    "num_groups = df[\"group_id\"].nunique()\n",
    "print(\"Number of groups (pattern segments):\", num_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0e7a19b-68b1-4f52-aeae-291943980f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (201, 64, 6)\n",
      "y shape: (201,)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_COLS = [\"price\", \"close\", \"high\", \"low\", \"open\", \"r\"]\n",
    "SEQ_LEN = 64\n",
    "\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "\n",
    "for gid, group in df.groupby(\"group_id\"):\n",
    "    label = group[\"pattern\"].iloc[0]\n",
    "    \n",
    "    # Extract selected features\n",
    "    feat = group[FEATURE_COLS].values  # shape: (group_len, num_features)\n",
    "\n",
    "    # Handle missing r if there are any:\n",
    "    # (optional) you can fill NaN in r with 0 before this loop:\n",
    "    # df[\"r\"] = df[\"r\"].fillna(0)\n",
    "\n",
    "    # Make fixed-length sequence\n",
    "    if len(feat) >= SEQ_LEN:\n",
    "        # take last 64 rows of this group\n",
    "        seq = feat[-SEQ_LEN:]\n",
    "    else:\n",
    "        # pad at the beginning by repeating the first row\n",
    "        pad_len = SEQ_LEN - len(feat)\n",
    "        pad = np.repeat(feat[0:1, :], pad_len, axis=0)\n",
    "        seq = np.concatenate([pad, feat], axis=0)\n",
    "\n",
    "    X_sequences.append(seq)\n",
    "    y_labels.append(label)\n",
    "\n",
    "X = np.stack(X_sequences)  # shape: (num_groups, SEQ_LEN, num_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "299c3015-d798-4a69-b848-0780dfb4016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hp shape: (116, 64, 6)\n",
      "y_hp shape: (116,)\n",
      "Classes: ['BearBat' 'BearButterfly' 'BearCrab' 'BearCypher' 'BearGartley'\n",
      " 'BearShark' 'BullBat' 'BullButterfly' 'BullCrab' 'BullCypher'\n",
      " 'BullGartley' 'BullShark']\n",
      "Encoded labels example: [ 7  2  2  2  7 10  3  8  7  4]\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop \"no-pattern\" sequences\n",
    "mask = y != \"no-pattern\"\n",
    "X_hp = X[mask]      # harmonic pattern sequences only\n",
    "y_hp = y[mask]      # corresponding labels\n",
    "\n",
    "print(\"X_hp shape:\", X_hp.shape)\n",
    "print(\"y_hp shape:\", y_hp.shape)\n",
    "\n",
    "# 2. Label encode the harmonic pattern names\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_hp)\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "print(\"Encoded labels example:\", y_encoded[:10])\n",
    "num_classes = len(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a3f769c-ddb0-4d59-ac72-ba20ddec1bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts at SEQUENCE level:\n",
      "Counter({'BullButterfly': 18, 'BearShark': 17, 'BullBat': 16, 'BearButterfly': 15, 'BullGartley': 10, 'BearCrab': 9, 'BullShark': 9, 'BullCrab': 8, 'BearGartley': 6, 'BearCypher': 4, 'BullCypher': 3, 'BearBat': 1})\n",
      "\n",
      "Encoded label counts at SEQUENCE level:\n",
      "Counter({7: 18, 5: 17, 6: 16, 1: 15, 10: 10, 2: 9, 11: 9, 8: 8, 4: 6, 3: 4, 9: 3, 0: 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"Label counts at SEQUENCE level:\")\n",
    "print(Counter(y_hp))\n",
    "\n",
    "print(\"\\nEncoded label counts at SEQUENCE level:\")\n",
    "print(Counter(y_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e0c12e9-ed8c-4ed6-af86-3eeeeeeea41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (81, 64, 6) (81,)\n",
      "Val:   (17, 64, 6) (17,)\n",
      "Test:  (18, 64, 6) (18,)\n"
     ]
    }
   ],
   "source": [
    "# Since there is only 1 sequence of BearBat, we cannot use stratify this time. So we will skip it for now and use it when we try Oversampling\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_hp, y_encoded,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a03f8ed-cd9f-4e77-93b2-7595b0b5b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train shape: (81, 64, 6) (81,)\n",
      "Resampled train shape: (165, 64, 6) (165,)\n"
     ]
    }
   ],
   "source": [
    "# Flatten sequences so RandomOverSampler can work: (samples, features_flat)\n",
    "nsamples, seqlen, nfeat = X_train.shape\n",
    "X_train_flat = X_train.reshape(nsamples, seqlen * nfeat)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res_flat, y_train_res = ros.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "# Reshape back to (samples, timesteps, features)\n",
    "X_train_res = X_train_res_flat.reshape(-1, seqlen, nfeat)\n",
    "\n",
    "print(\"Original train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Resampled train shape:\", X_train_res.shape, y_train_res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25a6e3d6-2876-4edf-a8f5-eb6959128b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standartization step\n",
    "\n",
    "# X_train, X_val, X_test currently have shape: (samples, 64, 6)\n",
    "num_features = X_train.shape[2]\n",
    "SEQ_LEN = X_train.shape[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on TRAIN ONLY (important! no data leakage)\n",
    "X_train_2d = X_train.reshape(-1, num_features)  # (81*64, 6)\n",
    "scaler.fit(X_train_2d)\n",
    "\n",
    "# Transform train/val/test\n",
    "def transform_with_scaler(X, scaler):\n",
    "    s, t, f = X.shape  # samples, timesteps, features\n",
    "    X_2d = X.reshape(-1, f)\n",
    "    X_scaled_2d = scaler.transform(X_2d)\n",
    "    return X_scaled_2d.reshape(s, t, f)\n",
    "\n",
    "X_train_scaled = transform_with_scaler(X_train, scaler)\n",
    "X_val_scaled   = transform_with_scaler(X_val, scaler)\n",
    "X_test_scaled  = transform_with_scaler(X_test, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21ddbe12-c3f2-4cea-b175-a6287e5ef5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m18,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m780\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,116</span> (90.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,116\u001b[0m (90.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,116</span> (90.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,116\u001b[0m (90.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Keeping the LSTM simple because our dataset is small\n",
    "\n",
    "num_classes = len(le.classes_)   # should be 12\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQ_LEN, num_features)),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "975df227-2a81-4182-8515-4521a7cba45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.0864 - loss: 2.5268 - val_accuracy: 0.1176 - val_loss: 2.4412\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1605 - loss: 2.4449 - val_accuracy: 0.2941 - val_loss: 2.4275\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1728 - loss: 2.4188 - val_accuracy: 0.2353 - val_loss: 2.4146\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1605 - loss: 2.3882 - val_accuracy: 0.2353 - val_loss: 2.4093\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2099 - loss: 2.3600 - val_accuracy: 0.2941 - val_loss: 2.4069\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2222 - loss: 2.3328 - val_accuracy: 0.2353 - val_loss: 2.3995\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2593 - loss: 2.2778 - val_accuracy: 0.2353 - val_loss: 2.3956\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2593 - loss: 2.2570 - val_accuracy: 0.2353 - val_loss: 2.4056\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2469 - loss: 2.2594 - val_accuracy: 0.2353 - val_loss: 2.4312\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1975 - loss: 2.2188 - val_accuracy: 0.2353 - val_loss: 2.4512\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2840 - loss: 2.1307 - val_accuracy: 0.2353 - val_loss: 2.4591\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1975 - loss: 2.2586 - val_accuracy: 0.2353 - val_loss: 2.4540\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de936064-1df5-457f-aa35-86c0d87f9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002B846DBCD60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BearBat       0.00      0.00      0.00         1\n",
      "BearButterfly       0.00      0.00      0.00         5\n",
      "     BearCrab       0.00      0.00      0.00         2\n",
      "   BearCypher       0.00      0.00      0.00         0\n",
      "  BearGartley       0.00      0.00      0.00         0\n",
      "    BearShark       0.10      0.50      0.17         2\n",
      "      BullBat       0.00      0.00      0.00         0\n",
      "BullButterfly       0.00      0.00      0.00         4\n",
      "     BullCrab       0.00      0.00      0.00         2\n",
      "   BullCypher       0.00      0.00      0.00         0\n",
      "  BullGartley       0.00      0.00      0.00         2\n",
      "    BullShark       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.06        18\n",
      "    macro avg       0.01      0.04      0.01        18\n",
      " weighted avg       0.01      0.06      0.02        18\n",
      "\n",
      "Confusion matrix:\n",
      "[[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "labels = np.arange(num_classes)  # [0, 1, ..., 11]\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    target_names=le.classes_,\n",
    "    zero_division=0   # avoid warnings for classes with no samples\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2122ed-630b-4985-9896-8d2637e65db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
